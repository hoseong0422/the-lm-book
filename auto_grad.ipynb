{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW41K1ji8MBD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn # 신경망 층 관련\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([\n",
        "    [22, 25], [25, 35], [47, 80], [52, 95], [46, 82], [56, 90],\n",
        "    [23, 27], [30, 50], [40, 60], [39, 57], [53, 95], [48, 88]\n",
        "], dtype=torch.float32) # 정수로 입력하면 모델훈련시 오류 발생하여 float32"
      ],
      "metadata": {
        "id": "0l60qb_K8k9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor([\n",
        "    [0], [0], [1], [1], [1], [1], [0], [1], [1], [0], [1], [1]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "n1_KoTNQ9UcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "id": "UnTkrDvc9VX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "SQHCLo139laO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1), # 입력특성 2개, 출력은 1개\n",
        "    nn.Sigmoid() # 이진 분류를 위해 사용\n",
        ")"
      ],
      "metadata": {
        "id": "F9OhP7gq91Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model # 모델 구조"
      ],
      "metadata": {
        "id": "mrpPBNOk9m-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(model[0].named_parameters()) # 가중치, 편향 들어있음"
      ],
      "metadata": {
        "id": "RwRKAOIV-M3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model[0].named_parameters())\n",
        "params[0][1].shape # 리니어층은 출력 크기가 앞, 입력의 크기가 뒤에 온다"
      ],
      "metadata": {
        "id": "nwNA7ULS-KIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001) # SGD 사용 lr(학습율)\n",
        "criterion = nn.BCELoss() # 손실 함수 정의"
      ],
      "metadata": {
        "id": "QGYnZZtx-eOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(500): # 모델의 입력과 정답값을 함께 지정하면 손실이 리턴\n",
        "  optimizer.zero_grad()\n",
        "  loss = criterion(model(inputs), labels)\n",
        "  loss.backward()\n",
        "  optimizer.step() # 손실을 역전파한 후 역전파된 그래디언트를 사용하여 가중치 업데이트"
      ],
      "metadata": {
        "id": "6D_oaTA0_A5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_1 = torch.tensor([22., 50.])\n",
        "model(sample_1)"
      ],
      "metadata": {
        "id": "nLjNNOsHADtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_2 = torch.tensor([50., 10.])\n",
        "with torch.no_grad():\n",
        "  print(model(sample_2))"
      ],
      "metadata": {
        "id": "AGmpAY9WAMo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid를 빼고 만들어보기\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1)\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# 로짓 : 신경망 모델의 마지막 선형층의 결과, 시그모이드 결과 통과전의 값, 크로스 엔트로피 로스를 로짓을 사용하는 바이너리 크로스 엔트로피 로스 사용\n",
        "# -> 이렇게 하는 이유 : 시그모이드 함수에 들어가는 지수함수를 처리할때 수치적으로 안정된 결과를 얻을 수 있고 최적화하기 더 유리하여 모델의 로짓을 사용하여 손실을 계산하기도 함"
      ],
      "metadata": {
        "id": "C_Rfrq5IAtQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(500): # 모델의 입력과 정답값을 함께 지정하면 손실이 리턴\n",
        "  optimizer.zero_grad()\n",
        "  loss = criterion(model(inputs), labels)\n",
        "  loss.backward()\n",
        "  optimizer.step() # 손실을 역전파한 후 역전파된 그래디언트를 사용하여 가중치 업데이트"
      ],
      "metadata": {
        "id": "cfjJjvaRDOpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logit = model(sample_1)\n",
        "  print(logit)"
      ],
      "metadata": {
        "id": "Wm7Wug9JDPQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이진분류이나 0~1사이 값이 아닌 결과가 나온 상황, 출력값이 logit\n",
        "torch.sigmoid(logit) # 명시적으로 sigmoid 함수 사용"
      ],
      "metadata": {
        "id": "FQAZwoHIDUaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RRWnYA-DnpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}